### Part a: Assessing Prompt Response
Using the Transformer model, the LLM returned Bismuth, Silicon, and Germanium as the three inorganic solids with the lowest thermal conductivity; however, these materials actually have moderate or even high thermal conductivity, and the citations provided by the model were fabricated. In contrast, experimentally verified low-thermal-conductivity inorganic crystals include TaVO₅ (~0.3 W/m·K), Ag₂S in its low-temperature phase (0.2–0.4 W/m·K), and WTe₂ (~0.8 W/m·K). The comparison shows that the LLM confidently produced incorrect scientific information and failed to identify genuinely low-k materials, demonstrating that such models often hallucinate quantitative data and must be validated against real experimental literature.

### Part b: Tokenization
I would recommend using the GPT-2 tokenizer. Compared with the other tokenizers, GPT-2’s byte-pair encoding handles materials-science terminology more effectively by splitting complex scientific words and chemical formulas into meaningful subword units rather than breaking them into individual characters. This results in fewer tokens, better preservation of chemical structure (e.g., CH₃NH₃PbI₃), and more efficient downstream processing. Other tokenizers such as T5 or byte-level tokenizers tend to over-fragment scientific expressions, which reduces semantic coherence. Therefore, GPT-2 provides the most balanced and practical tokenization for materials-science text.

### Part c: Masked Language Models
I selected MoS₂ as the material and provided the masked language model (BERT-base-uncased) with several of its key properties, including its layered structure, strong light–matter interaction, 1.8 eV direct bandgap, and high carrier mobility. When predicting the masked token, the model produced outputs such as “electronics,” “aerospace,” “medicine,” and “telecommunications.” These terms represent broad industrial sectors rather than realistic applications of MoS₂, whose true uses include photodetectors, field-effect transistors, and sensors. Therefore, the model’s prediction is not accurate, demonstrating that general-purpose masked language models struggle to infer specific material applications from scientific property descriptions.